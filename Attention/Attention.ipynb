{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch.functional as F\n",
    "import torch\n",
    "from torch.nn import functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7728, -0.7551,  0.3917,  0.5440],\n",
      "        [ 1.0195, -0.2443, -0.5720,  2.9042],\n",
      "        [ 0.7307, -0.9481,  1.0065,  1.0238]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ebd = torch.nn.Embedding(10, 4) # 10 words in vocab, 4 dimensional embeddings\n",
    "\n",
    "words_index = torch.LongTensor([0, 3, 9])\n",
    "\n",
    "words_ebd = ebd(words_index)\n",
    "\n",
    "print(words_ebd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2403, -0.0713,  0.6862,  0.4640],\n",
      "        [ 0.0478, -0.2400,  1.5110,  1.5108],\n",
      "        [-0.5272, -0.3186,  1.1340,  0.6403]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "q_lin = torch.nn.Linear(4, 4)\n",
    "q = q_lin(words_ebd)\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a attention demo code\n",
    "def attention(q, k, v):\n",
    "    #q, k, v shape: (batch_size, seq_len, dim)\n",
    "    score = q @ k.transpose(1, 2)\n",
    "    score = score / (k.size(-1) ** 0.5)\n",
    "    score = F.softmax(score, dim=-1)\n",
    "    output = score @ v\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3414,  1.0665,  0.0343,  0.0175],\n",
      "         [-0.4733,  0.9483,  0.7029,  0.4372],\n",
      "         [-0.2108,  0.9628,  0.5640, -0.3139],\n",
      "         [-0.6945,  0.2593,  0.9004,  0.6061],\n",
      "         [-0.2245,  0.1200,  0.4361,  0.9039]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 5\n",
    "dim = 4\n",
    "\n",
    "q = torch.randn(batch_size, seq_len, dim)\n",
    "k = torch.randn(batch_size, seq_len, dim)\n",
    "v = torch.randn(batch_size, seq_len, dim)\n",
    "\n",
    "output = attention(q, k, v)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3280, -1.2238,  0.7824,  1.0099],\n",
      "         [-0.1306,  0.0089, -0.4798, -0.0866],\n",
      "         [-0.2321,  0.0260, -0.4015, -0.5406],\n",
      "         [-0.0350, -0.0666, -0.6470,  0.2620],\n",
      "         [ 0.0600, -0.1234, -0.8371,  0.4399]]])\n",
      "tensor([[[ 0.3280, -1.2238,  0.7824,  1.0099],\n",
      "         [-0.1306,  0.0089, -0.4798, -0.0866],\n",
      "         [-0.2321,  0.0260, -0.4015, -0.5406],\n",
      "         [-0.0350, -0.0666, -0.6470,  0.2620],\n",
      "         [ 0.0600, -0.1234, -0.8371,  0.4399]]])\n"
     ]
    }
   ],
   "source": [
    "# use the attention function, comparing the result with F.scale_dot_product_attention\n",
    "def test_attention():\n",
    "    batch_size = 1\n",
    "    seq_len = 5\n",
    "    dim = 4\n",
    "    \n",
    "    q = torch.randn(batch_size, seq_len, dim)\n",
    "    k = torch.randn(batch_size, seq_len, dim)\n",
    "    v = torch.randn(batch_size, seq_len, dim)\n",
    "    \n",
    "    \n",
    "    output = attention(q, k, v)\n",
    "    print(output)\n",
    "    \n",
    "    output2 = F.scaled_dot_product_attention(q, k, v)\n",
    "    print(output2)\n",
    "    \n",
    "    assert torch.allclose(output, output2)\n",
    "    \n",
    "test_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
